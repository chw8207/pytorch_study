{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zdku12ZrBt4OepuANxlNRfFJfQygOKSJ",
      "authorship_tag": "ABX9TyO4PbOxzUMh8FwNYtcELGnu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chw8207/pytorch_study/blob/main/softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn25jRRxu2Dr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7UEhdKavTpQ",
        "outputId": "84553d5c-b232-46d2-d0ca-43e43c8a6772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe28d36b650>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  파이토치로 소프트맥스의 비용 함수 구현하기 (로우-레벨)"
      ],
      "metadata": {
        "id": "6Z_aXTPCvYe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.FloatTensor([1,2,3])"
      ],
      "metadata": {
        "id": "AVblxAafvZrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서를 소프트맥스 함수 입력으로 사용하고 확인해보기\n",
        "hypothesis = F.softmax(z, dim=0)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqgCXyC3vnrY",
        "outputId": "283f9e5d-4160-43bd-e851-78bd4be23329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원소들의 값의 합이 1인지 확인해보기\n",
        "hypothesis.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjkDU4u5v49Y",
        "outputId": "e99fdff9-2ac9-4c9d-b843-a9c8a55cb1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 3X5행렬의 크기를 가진 텐서 선언\n",
        "z = torch.rand(3,5, requires_grad=True)"
      ],
      "metadata": {
        "id": "dWVQ9CcJwFlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서에 소프트맥스함수 적용\n",
        "# 텐서 차원이 2차원이라 두 번째 차원 : dim=1\n",
        "hypothesis = F.softmax(z, dim=1)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gZKBOlPyLXm",
        "outputId": "a656bd97-cf32-486f-faa9-ff860426f93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
            "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
            "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 샘플에 대한 임의의 레이블 만들기\n",
        "y = torch.randint(5,(3,)).long()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH5RaZVQ9SkE",
        "outputId": "452e9939-aeea-459d-dcef-2df359807423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 원소가 0의 값을 가진 3 × 5 텐서 생성\n",
        "y_one_hot = torch.zeros_like(hypothesis)\n",
        "y_one_hot.scatter_(1,y.unsqueeze(1),1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWfvKBij9izX",
        "outputId": "f8027dbc-3e2a-4c49-badf-f7300d8d46ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 비용함수 구현하기\n",
        "cost = (y_one_hot*-torch.log(hypothesis)).sum(dim=1).mean()\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qvogub2CKb4",
        "outputId": "e5c3860f-1430-4d0f-f2c1-1d634f29348c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6682, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  파이토치로 소프트맥스의 비용 함수 구현하기 (하이-레벨)"
      ],
      "metadata": {
        "id": "wRFzFDVNFVHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(y_one_hot*-F.log_softmax(z,dim=1)).sum(dim=1).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkwZp1toFWky",
        "outputId": "7fb4f65f-662d-4cca-ceda-05099d75de8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6682, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F.nll_loss()를 사용할 때는 원-핫 벡터를 넣을 필요없이 바로 실제값을 인자로 사용\n",
        "# High level\n",
        "F.nll_loss(F.log_softmax(z, dim=1),y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXT1MtnOIHPS",
        "outputId": "159142a0-e1b6-46bb-f05f-8cea741601e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6682, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F.log_softmax() + F.nll_loss() = F.cross_entropy()\n",
        "F.cross_entropy(z,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LnkhFeYIyHT",
        "outputId": "cf69085b-7ec8-4dcb-9398-8b823811ba94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6682, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 소프트맥스 회귀 구현하기\n",
        " - 로우-레벨, F.cross_entropy"
      ],
      "metadata": {
        "id": "fk1D6ygZJGL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "w-gHsOHdJNDF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQqheG4YJaO5",
        "outputId": "2faf269e-9969-4e1a-df98-eb912b4d92a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9d8c713650>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터와 레이블을 텐서로 선언\n",
        "X_train = [[1,2,1,1],\n",
        "           [2,1,3,2],\n",
        "           [3,1,3,4],\n",
        "           [4,1,5,5],\n",
        "           [1,7,5,5],\n",
        "           [1,2,5,6],\n",
        "           [1,6,6,6],\n",
        "           [1,7,7,7]]\n",
        "y_train = [2,2,2,1,1,1,0,0]\n",
        "\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.FloatTensor(y_train)"
      ],
      "metadata": {
        "id": "h1NYUZaKJyWw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 소프트맥스회귀(로우-레벨)\n",
        "# 크기 확인\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am_IDRO-KiUd",
        "outputId": "486c37e9-455b-4095-e6d6-99f892149f6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4])\n",
            "torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot = torch.zeros(8,3)\n",
        "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1).type(torch.int64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "WabPRrprMFgJ",
        "outputId": "aac2e222-0fc2-4898-e6dc-8491590510f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c8867ea024c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: scatter(): Expected dtype int64 for index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 소프트맥스회귀(하이-레벨)\n",
        "# 모델 초기화\n",
        "W = torch.zeros((4,3), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr=0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1) : \n",
        "  # cost 계산\n",
        "  z = X_train.matmul(W) + b\n",
        "  cost = F.cross_entropy(z, y_train.long())\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0 : \n",
        "    print(f'Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFUs5LmecQ-n",
        "outputId": "29e90997-1314-425a-aea6-02dcbf1433f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.761050\n",
            "Epoch  200/1000 Cost: 0.689991\n",
            "Epoch  300/1000 Cost: 0.643229\n",
            "Epoch  400/1000 Cost: 0.604117\n",
            "Epoch  500/1000 Cost: 0.568256\n",
            "Epoch  600/1000 Cost: 0.533922\n",
            "Epoch  700/1000 Cost: 0.500291\n",
            "Epoch  800/1000 Cost: 0.466908\n",
            "Epoch  900/1000 Cost: 0.433507\n",
            "Epoch 1000/1000 Cost: 0.399962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 소프트맥스 회귀 nn.Module로 구현\n",
        " - output_dim : 클래스의 개수"
      ],
      "metadata": {
        "id": "lm_GIgZIeMhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 선언 및 초기화\n",
        "# 4개의 특성을 가지고 3개의 클래스로 분류\n",
        "model = nn.Linear(4,3)"
      ],
      "metadata": {
        "id": "EXuJBC0beN08"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1) : \n",
        "  # H(x) 계산\n",
        "  prediction = model(X_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost = F.cross_entropy(prediction, y_train.long())\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%20==0 : \n",
        "    print(f'Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdORRmvLe06h",
        "outputId": "28cffebe-c057-43ec-a513-a077191cd35f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.616785\n",
            "Epoch   20/1000 Cost: 0.904600\n",
            "Epoch   40/1000 Cost: 0.778017\n",
            "Epoch   60/1000 Cost: 0.722806\n",
            "Epoch   80/1000 Cost: 0.686341\n",
            "Epoch  100/1000 Cost: 0.658891\n",
            "Epoch  120/1000 Cost: 0.636713\n",
            "Epoch  140/1000 Cost: 0.617946\n",
            "Epoch  160/1000 Cost: 0.601539\n",
            "Epoch  180/1000 Cost: 0.586845\n",
            "Epoch  200/1000 Cost: 0.573443\n",
            "Epoch  220/1000 Cost: 0.561047\n",
            "Epoch  240/1000 Cost: 0.549451\n",
            "Epoch  260/1000 Cost: 0.538507\n",
            "Epoch  280/1000 Cost: 0.528102\n",
            "Epoch  300/1000 Cost: 0.518151\n",
            "Epoch  320/1000 Cost: 0.508588\n",
            "Epoch  340/1000 Cost: 0.499357\n",
            "Epoch  360/1000 Cost: 0.490416\n",
            "Epoch  380/1000 Cost: 0.481729\n",
            "Epoch  400/1000 Cost: 0.473265\n",
            "Epoch  420/1000 Cost: 0.465000\n",
            "Epoch  440/1000 Cost: 0.456911\n",
            "Epoch  460/1000 Cost: 0.448979\n",
            "Epoch  480/1000 Cost: 0.441185\n",
            "Epoch  500/1000 Cost: 0.433516\n",
            "Epoch  520/1000 Cost: 0.425956\n",
            "Epoch  540/1000 Cost: 0.418493\n",
            "Epoch  560/1000 Cost: 0.411114\n",
            "Epoch  580/1000 Cost: 0.403807\n",
            "Epoch  600/1000 Cost: 0.396563\n",
            "Epoch  620/1000 Cost: 0.389370\n",
            "Epoch  640/1000 Cost: 0.382218\n",
            "Epoch  660/1000 Cost: 0.375097\n",
            "Epoch  680/1000 Cost: 0.367999\n",
            "Epoch  700/1000 Cost: 0.360914\n",
            "Epoch  720/1000 Cost: 0.353833\n",
            "Epoch  740/1000 Cost: 0.346748\n",
            "Epoch  760/1000 Cost: 0.339651\n",
            "Epoch  780/1000 Cost: 0.332535\n",
            "Epoch  800/1000 Cost: 0.325392\n",
            "Epoch  820/1000 Cost: 0.318218\n",
            "Epoch  840/1000 Cost: 0.311008\n",
            "Epoch  860/1000 Cost: 0.303762\n",
            "Epoch  880/1000 Cost: 0.296482\n",
            "Epoch  900/1000 Cost: 0.289178\n",
            "Epoch  920/1000 Cost: 0.281874\n",
            "Epoch  940/1000 Cost: 0.274610\n",
            "Epoch  960/1000 Cost: 0.267463\n",
            "Epoch  980/1000 Cost: 0.260570\n",
            "Epoch 1000/1000 Cost: 0.254148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 소프트맥스 회귀 클래스로 구현"
      ],
      "metadata": {
        "id": "3V2YYR1RhbBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftMaxClassifierModel(nn.Module) : \n",
        "  def __init__(self) : \n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4,3)\n",
        "\n",
        "  def forward(self, X) : \n",
        "    return self.linear(X)"
      ],
      "metadata": {
        "id": "KoCLKVFBhb5M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftMaxClassifierModel()"
      ],
      "metadata": {
        "id": "RsnjTxKciHOf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs+1) : \n",
        "  # H(x) 계산\n",
        "  prediction = model(X_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost = F.cross_entropy(prediction, y_train.long())\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%20==0 : \n",
        "    print(f'Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOwzVrA8iv9t",
        "outputId": "9aec9f6f-e0dc-4ddf-e212-d02a7421c7ed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.476262\n",
            "Epoch   20/1000 Cost: 0.950686\n",
            "Epoch   40/1000 Cost: 0.832654\n",
            "Epoch   60/1000 Cost: 0.771019\n",
            "Epoch   80/1000 Cost: 0.732903\n",
            "Epoch  100/1000 Cost: 0.705964\n",
            "Epoch  120/1000 Cost: 0.684907\n",
            "Epoch  140/1000 Cost: 0.667274\n",
            "Epoch  160/1000 Cost: 0.651812\n",
            "Epoch  180/1000 Cost: 0.637822\n",
            "Epoch  200/1000 Cost: 0.624880\n",
            "Epoch  220/1000 Cost: 0.612713\n",
            "Epoch  240/1000 Cost: 0.601137\n",
            "Epoch  260/1000 Cost: 0.590021\n",
            "Epoch  280/1000 Cost: 0.579271\n",
            "Epoch  300/1000 Cost: 0.568815\n",
            "Epoch  320/1000 Cost: 0.558599\n",
            "Epoch  340/1000 Cost: 0.548581\n",
            "Epoch  360/1000 Cost: 0.538727\n",
            "Epoch  380/1000 Cost: 0.529011\n",
            "Epoch  400/1000 Cost: 0.519410\n",
            "Epoch  420/1000 Cost: 0.509906\n",
            "Epoch  440/1000 Cost: 0.500485\n",
            "Epoch  460/1000 Cost: 0.491133\n",
            "Epoch  480/1000 Cost: 0.481839\n",
            "Epoch  500/1000 Cost: 0.472595\n",
            "Epoch  520/1000 Cost: 0.463391\n",
            "Epoch  540/1000 Cost: 0.454222\n",
            "Epoch  560/1000 Cost: 0.445080\n",
            "Epoch  580/1000 Cost: 0.435962\n",
            "Epoch  600/1000 Cost: 0.426860\n",
            "Epoch  620/1000 Cost: 0.417772\n",
            "Epoch  640/1000 Cost: 0.408694\n",
            "Epoch  660/1000 Cost: 0.399623\n",
            "Epoch  680/1000 Cost: 0.390556\n",
            "Epoch  700/1000 Cost: 0.381490\n",
            "Epoch  720/1000 Cost: 0.372426\n",
            "Epoch  740/1000 Cost: 0.363362\n",
            "Epoch  760/1000 Cost: 0.354298\n",
            "Epoch  780/1000 Cost: 0.345236\n",
            "Epoch  800/1000 Cost: 0.336179\n",
            "Epoch  820/1000 Cost: 0.327134\n",
            "Epoch  840/1000 Cost: 0.318107\n",
            "Epoch  860/1000 Cost: 0.309112\n",
            "Epoch  880/1000 Cost: 0.300169\n",
            "Epoch  900/1000 Cost: 0.291307\n",
            "Epoch  920/1000 Cost: 0.282573\n",
            "Epoch  940/1000 Cost: 0.274038\n",
            "Epoch  960/1000 Cost: 0.265819\n",
            "Epoch  980/1000 Cost: 0.258095\n",
            "Epoch 1000/1000 Cost: 0.251128\n"
          ]
        }
      ]
    }
  ]
}